##########  GBDT
import math
import random
import numpy as np
import pandas as pd
from xgboost import plot_tree
import matplotlib.pyplot as plt
from lightgbm import LGBMRegressor
from sklearn.model_selection import KFold
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error 
from sklearn.metrics import r2_score 
from catboost import CatBoostRegressor
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
##load data
data = pd.read_excel('Data.xlsx')
data = np.array(data)
X = data[ : , :5]
Y = data[ : ,5].flatten()
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,Y,train_size=0.85)
##Hyperparameters optimization
from sklearn.model_selection import KFold#这个函数只能用于

paramgrid = {"learning_rate": [i*0.01 for i in range(1,31)],
             "n_estimators" : range(100,1000,10),
             "max_depth" : range(2,12),
            'min_samples_split':range(2,11),
            'subsample':[i*0.01 for i in range(80,100)]
            }
random.seed(1)
from sklearn.model_selection import cross_validate
from evolutionary_search import EvolutionaryAlgorithmSearchCV
cv = EvolutionaryAlgorithmSearchCV(estimator=GradientBoostingRegressor(),
                                   params=paramgrid, #超参数搜索空间
                                   #scoring="neg_root_mean_squared_error", #RMSE的标准
                                   scoring="r2", #R2的标准
                                   cv=KFold(n_splits=5), #交叉验证5折
                                   verbose=1,
                                   population_size=100, #整个种群的染色体数目为50个超参数组合
                                   gene_mutation_prob=0.20, #我们的“孩子”超参数组合中每次会大概选择出10%的超参数进行随机取值
                                   gene_crossover_prob=0.5, #我们会选择每一条“父母”染色体（超参数组合）中的50%的基因（超参数）进行相互交叉
                                   tournament_size=3, #每次从上一代中选择出适应度最好的3个超参数组合直接进行 “复制”
                                   generations_number=50,
                                   n_jobs=1)
cv.fit(x_train, y_train)

##train model
import time
time_start=time.time()
gbr = GradientBoostingRegressor(n_estimators=1060, max_depth=5, min_samples_split=8, learning_rate=0.1,subsample=0.84
                                ,loss='ls',min_samples_leaf=1,min_weight_fraction_leaf=0,min_impurity_split=None,
                                init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None)
gbr.fit(x_train, y_train)
y_predict = gbr.predict(x_test)
y_predict1 = gbr.predict(x_train)
error1=(y_test-y_predict)/y_test
#print(y_predict)
#print(y_test)
print(abs(error1))
MSE1 = mean_squared_error(y_test,y_predict)
RMSE1 = math.sqrt(MSE1)
MSE2 = mean_squared_error(y_train,y_predict1)
RMSE2 = math.sqrt(MSE2)
R2 = r2_score(y_test,y_predict)
n1 = len(y_test)
n2 = len(y_train)
mape1 = sum(np.abs((y_test - y_predict)/y_test))/n1*100
mape2 = sum(np.abs((y_train - y_predict1)/y_train))/n2*100
print(mape1,mape2)
print(f'MSE的值为{MSE1},RMSE为{RMSE1},R2为{R2}')
print(r2_score(y_train,y_predict1),RMSE2)
##save data
from openpyxl.workbook import Workbook
from openpyxl.writer.excel import ExcelWriter
wb = Workbook()
ws = wb.active
ws.title = u'GBDT'
data2=[y_predict,y_test,error1,y_predict1,y_train]
i = 1
r = 1
for line in data2:
    for col in range(1, len(line) + 1):
        ColNum = r
        ws.cell(row=r, column=col).value = line[col - 1]
    i += 1
    r += 1
wb.save('test_GBDT.xlsx')
time_end=time.time()
print('totally cost',time_end-time_start)
##sub_cart tree

##importance of variables
import matplotlib.pyplot as plt
importance = gbr.feature_importances_
Impt_Series = pd.Series(importance, index = data.iloc[:,:5].columns)
print(Impt_Series)
Impt_Series = Impt_Series.sort_values(ascending = True)
print(Impt_Series)
print(list(Impt_Series.index))
Y = list(Impt_Series.index)
plt.figure(figsize=(10,5)) 
plt.barh(range(len(Y)), 
        Impt_Series.values, 
        tick_label = Y, 
        color = 'steelblue', 
       )
print(Impt_Series.values)
# print()
for y,x in enumerate(Impt_Series.values):
    plt.text(x+0.0001,y,'%s' %round(x,3),va='center')
plt.show()
